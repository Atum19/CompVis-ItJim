{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d92b112e-842d-4343-a435-a83fb8c4449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import pylab\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8df15ed-a2ff-474e-ba49-d7e9a198cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filename = '../images_hm_task1/hearts 2.png'\n",
    "img_bgr = cv2.imread(image_filename)\n",
    "img_bgr = cv2.resize(img_bgr, (img_bgr.shape[1] // 2, img_bgr.shape[0] // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea5cba3-3431-45cd-b52c-fb11c4f45943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion of the image into another color space\n",
    "img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "253dfa63-2de2-45e4-90f3-ec154604fa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add text and show the initial image\n",
    "# im_to_show = img_gray.copy()\n",
    "# im_to_show = cv2.putText(im_to_show, 'Initial image', (50, 50),\n",
    "#                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "# cv2.imshow('', im_to_show)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyWindow('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21361ba9-1cc0-4065-bd0c-c1795bd7a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eq_gorilla = cv2.equalizeHist(img_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a0cf3b8-4a48-4505-8140-692ee7f07ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('', eq_gorilla)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyWindow('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65877702-23e0-4632-99bc-7a80d43681de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32ecc5de-b2a0-456c-b465-167d8778195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply adaptive Gaussian threshold\n",
    "img_thresh = cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 55, 0.1)\n",
    "\n",
    "# Add text and show the threshold image\n",
    "img_thresh = cv2.cvtColor(img_thresh, cv2.COLOR_GRAY2BGR)\n",
    "img_thresh = cv2.putText(img_thresh, 'Adaptive Gaussian threshold', (50, 50),\n",
    "                         cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "# cv2.imshow('', img_thresh)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyWindow('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c03c2f8-5abe-4386-8b18-c1e704d3bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bin = cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 55, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "448f9a43-1f0b-4ed4-88c2-2a25ee1dc245",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((2,2),np.uint8) # * 255\n",
    "# erosion5 = cv2.erode(img,kernel,iterations = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e938959-557a-4d5e-91d1-e51637e0b9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f89378b-54ea-40d0-86c9-717906b2acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "closing = cv2.morphologyEx(img_bin, cv2.MORPH_CLOSE, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9deef3e-2b1b-440c-8bab-4fc1e2b6e87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('', closing)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d1f0931-d1aa-4bce-a961-10647418996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Dilation\n",
    "# img = cv2.dilate(closing, np.ones((2, 2), np.uint8), iterations=1)\n",
    "# cv2.imshow('', img)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# Erosion 1\n",
    "img = cv2.erode(closing, np.ones((2, 2), np.uint8), iterations=1)\n",
    "cv2.imshow('', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01889eda-0f00-4702-af3c-9018005ac259",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_b = cv2.resize(closing, (closing.shape[1] * 2, closing.shape[0] * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c41870f-b71f-413e-92aa-323dfccf215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('', img_b)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5661b01-80e8-4cda-b40e-f6bf0a20900f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf7db71-1357-415b-8bad-0b7186d94674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6549709d-91db-4c8b-9436-49b09cf99292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755fa2d0-64dd-41ca-8538-2fd3c9ec7cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3),np.uint8)\n",
    "gradient = cv2.morphologyEx(img,cv2.MORPH_GRADIENT,kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea4fec-3685-4f05-9dec-0aeb4ba54eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d78ec97-df39-4c99-81fb-ea7b1de09d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_gorilla = cv2.equalizeHist(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0c2505-eb83-40fa-aad1-8414428439af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('', eq_gorilla)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec89d3e1-cb8a-4a60-b696-c633580539e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d9bdd2-2c07-4343-b6da-1ee89aa64325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940716b0-4d98-4a8a-93a5-2eeb385cd086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba65225-adc8-4999-ad32-119918811552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion of the image into another color space\n",
    "img_gray = cv2.cvtColor(img_thresh, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8222d6da-7f5f-48dc-9d97-3e7c6701986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply simple threshold with various levels\n",
    "levels = [64, 128, 192]\n",
    "for level in levels:\n",
    "    ret, img_thresh = cv2.threshold(img_gray, level, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Add text and show the threshold image\n",
    "    img_thresh = cv2.cvtColor(img_thresh, cv2.COLOR_GRAY2BGR)\n",
    "    img_thresh = cv2.putText(img_thresh, 'Simple threshold level ' + str(level), (50, 50),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('', img_thresh)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09427a00-9744-4d5d-ab7f-f9899ff761b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb9901c-7e42-4062-87b2-41a7c3247f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0374dd97-039f-4df8-bec4-7033da8e32c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe008e-04c2-4b8d-ae66-2dd607a454c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_thresh = img_thresh.astype(np.uint8)\n",
    "# img_grey = img_grey.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3324fafb-ab6d-4162-9d04-1d0d694bf3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bin = cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 55, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7402a1-7ec5-41dd-b1d6-8ae92eb47795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dilation\n",
    "img = cv2.dilate(img_bin, np.ones((2, 2), np.uint8), iterations=1)\n",
    "cv2.imshow('', img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Erosion 1\n",
    "img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations=1)\n",
    "cv2.imshow('', img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Erosion 2\n",
    "img = cv2.erode(img, np.ones((3, 3), np.uint8), iterations=1)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "cv2.putText(img, 'Morphology result', (70, 70), 0, 1, [0, 0, 255], 3)\n",
    "cv2.imshow('', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83a7051-2b9b-4c75-99de-ff47700f8d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5a34da-27ad-48a9-bea5-35c76607a4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf23ca-c2a2-4c42-bb55-87bf91ff35da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a272be-6c30-4dea-aaef-d0ed8436a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Sobel gradients along both axes\n",
    "sobel_x = cv2.Sobel(img_thresh, cv2.CV_64F, 1, 0, ksize=5)\n",
    "sobel_y = cv2.Sobel(img_thresh, cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "# Join both result images to display simultaneously\n",
    "stack_image = np.hstack((sobel_x, sobel_y))\n",
    "\n",
    "# Take the normalized absolute value to show both positive and negative gradients\n",
    "stack_image = np.absolute(255 * stack_image / np.max(stack_image))\n",
    "stack_image = np.uint8(stack_image)\n",
    "\n",
    "# Show the Sobel gradient image\n",
    "cv2.imshow('', stack_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7244df-8d54-4016-af0e-a3929a297b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e19712-58b1-457b-9899-a1f08ef8f994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082d51c1-8496-4c07-a4fb-b678adbe2046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e3bce0-4a5c-406f-878a-93594916e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_grey2 = cv2.cvtColor(img_thresh, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b7531-d8ee-4a79-81cf-500ff17bd3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply adaptive mean threshold\n",
    "img_thresh = cv2.adaptiveThreshold(img_grey2, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 128, 1)\n",
    "\n",
    "# Add text and show the threshold image\n",
    "# img_thresh = cv2.cvtColor(img_thresh, cv2.COLOR_GRAY2BGR)\n",
    "img_thresh = cv2.putText(img_thresh, 'Adaptive mean threshold', (50, 50),\n",
    "                         cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "cv2.imshow('', img_thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951aedba-f800-4c6b-8dc6-2d6670d8d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_gray3 = cv2.cvtColor(img_thresh, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply simple threshold with various levels\n",
    "levels = [64, 128, 192]\n",
    "for level in levels:\n",
    "    ret, img_thresh = cv2.threshold(img_grey2, level, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Add text and show the threshold image\n",
    "    img_thresh = cv2.cvtColor(img_thresh, cv2.COLOR_GRAY2BGR)\n",
    "    img_thresh = cv2.putText(img_thresh, 'Simple threshold level ' + str(level), (50, 50),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('', img_thresh)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyWindow('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb161365-d4c1-456a-9160-b46377bfed33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c326dbf6-25ba-418e-88f7-eecceedb98f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad746e19-8026-4ca1-8069-07b428534a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18dcc82-c45a-452a-9e0a-af805abafcec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
